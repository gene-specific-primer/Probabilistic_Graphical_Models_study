* 模型的表示其来源可以由相应领域的专家给出，也可以直接从数据中学习到。如下所示：

![img](readme/representation_week_01.png)

* 模型的准确性具有不确定性主要是因为：对现实世界的描述不全面；观察到的数据有噪声；模型只是体现大部分的数据，对某些特例不会考虑；模型固有的不确定性。
* PGM模型在实际使用时需要考虑以下几个方面：
  * 表达阶段：有图模型还是无图模型，时序模型还是平面模型。
  * 推理阶段：近似推理还是确定推理，是否需要做出决定。
  * 学习阶段：是学习网络的参数还是连结构也需要学习，是否使用全部数据。
* 一个factor其实就是一个因果表，因果表中变量组成的集合称为scope。两个factor是可以相乘的，称为factor product. Factor也可以边缘化，即把表中边缘变量给求和积分掉。另外还可以从factor中提取出部分行，这种操作称为factor reduction。还可以根据新获得的evidence来更改factor的概率值。
* 在PGM模型中使用factor的原因是：在高维空间的数据分布中，factor是一个基本的模块。这些高维空间中的大数据也可以由小的factor相乘组成，并且一些基本的操作都是相通的。

### 编程作业：

* 这次实验是熟悉下SamIam这个软件，该软件是专门正对PGM的实际应用开发的，具体介绍和使用参考官网：<http://reasoning.cs.ucla.edu/samiam/index.php>。首先第一个小题就是构造一个贝叶斯网络图，节点已经给出，并且父子关系已经给出了文字描述，只需连线和给出条件概率表值。网络图如下所示：

![img](readme/representation_week_01_编程作业_SamIam.png)



* [机器学习&数据挖掘笔记_17（PGM练习一：贝叶斯网络基本操作](http://www.cnblogs.com/tornadomeet/archive/2013/05/12/3074329.html)









### 1.1 动机

- 本书主要关注涉及不确定性的复杂系统模型；
- 为了得到有意义的结论，我们不仅不要推理什么是可能的，而且需要推理什么是很可能的

### 1.2.1 概率图模型

![TIM图片20181210103829](readme/%E6%A6%82%E7%8E%87%E5%9B%BE%E6%A8%A1%E5%9E%8B_%E4%B8%8D%E5%90%8C%E8%A7%86%E8%A7%92.png)

- 图定义了紧凑表示高维分布的一种框架；
- 与其对问题中所有变量的可能取值的概率进行编码，不如将分布分解为一些更小的因子，使每个因子定义在一个更小的概率空间；
- 结果是这两种视角——图作为独立关系集合的表示与图作为分解分布的框架——在深层意义上是等价的
- 准确说，正是分布的独立特性才使得分布能够紧凑地以因子分解的形式表示。反之，分布的一个特别的因子分解确保了某些独立关系的成立，

### 1.2.2 表示、推理、学习

- 图模型优点
  1. 分布通常可以用便于处理的方式描述，甚至在联合分布的显式表示如天文数字般庞大的情况下也是如此，重要的是，由此框架提供的这类表示是透明的，因而专家可以理解并评估其语义和性质，对于构建一个准确的反映我们队问题理解的模型而言，这个性质是重要的，不透明的模型容易导致无法解释的，甚至不希望的答案；
  2. 如我们所表明的，相同的结构常常可以使分布有效地应用于推理中——把分布作为关于世界的模型来回答查询；
  3. 有助于这些模型的有效构造，无论是通过专家还是自动地，利用数据学习，一个模型能够提供对于我们过去经验的很好的额近似，



## 课程资料

#### introduction and overview

[Overview and Motivation](probabilistic_graphical_models/1.1.1-Intro-overview.pdf) Chapter 1.

[Distributions](probabilistic_graphical_models/1.1.2-Intro-distributions.pdf) Chapters 2.1.1 to 2.1.3.

[Factors](probabilistic_graphical_models/1.1.3-Intro-factors.pdf). Chapter 4.2.1.

### Bayesian Network Fundamentals

[Semantics and Factorization](probabilistic_graphical_models/2.1.1-Repn-BNs-semantics.pdf) Chapters 3.2.1, 3.2.2. 

[Reasoning Patterns](probabilistic_graphical_models/2.1.2-Repn-BNs-patterns.pdf). Chapter 3.2.1.

[Flow of Probabilistic Influence](probabilistic_graphical_models/2.1.3-Repn-BNs-flow-influence.pdf). Chapter 3.3.1.

### Bayesian Networks: Independencies

[Conditional Independence](probabilistic_graphical_models/2.1.4-Repn-Ind-conditional-independence.pdf). Chapters 2.1.4, 3.1.

[Independencies in Bayesian Networks](probabilistic_graphical_models/2.1.5-Repn-Ind-BNs.pdf). Chapter 3.2.2.

[Naive Bayes](probabilistic_graphical_models/2.1.6-Repn-BNs-NaiveBayes.pdf). Chapter 3.1.3.

### Bayesian Networks: Knowledge Engineering

[Application - Medical Diagnosis](probabilistic_graphical_models/2.1.7-Repn-BNs-diagnosis.pdf) Chapter 3.2: Box 3.D (p. 67).





## Q&A

### introduction and overview

#### Overview and Motivation

Q. PGM  what

A.  1. 利用复杂分布中的结构来紧凑表示它们

2. 使模型能够有效构造和利用



  Q. PGM how

  A. 1. 使用基于图表示来紧凑编码复杂分布在高维中的

  2. ![1547202550110](readme/representation-Overview-and-Motivation-how-PGM.png)





  Q. 图作为独立关系集合 VS 图作为分解分布的框架等价

  A. 1. 独立性允许在图紧凑表示分解形式

  2. 分布的特殊的分解形式保证了独立特性



  Q. 图表示的两大家族

  A. 1. Bayesian 有向图

  2. Markov network 无向图


Q. PGM表示 优点

A. 1. 允许分布写的有迹可循 --> 不透明模型导致无法解释，甚至不希望的答案

2. 同样的结构允许分布被使用有效的对于推断
3. 有助于这些模型的有效构造
   * 通过从数据中学习模型良好近似我们过去的经验
   * 数据驱动的模型，人类专家提供给定阈内指导



Q. 表示、推断和学习是智能系统最重要的几个组件

A. 1. 陈述描述是我们世界的合理的编码

2. 使用这个表示有效回答广泛感谢趣的问题
3. 需要这些分布，组合专家知识和积累的数据
4. PGM是小的模型支持这三个特性在广泛的问题上



#### Factors

Q. Factors what

A. 1. Markov 网络的参数化

2. 变量在辖阈范围内不同值之间兼容性的一个描述



Q. Factors how表示图

A. 1.  如何参数化图为一系列关联的factors

* 联系参数直接到图的边
*  允许factor任意变量的子集



Q. Factors 因子乘法

A. 1. X,Y,Z为三个不想交的变量集合，factors(X,Y,Z) = factors(X,Y) * factors(Z,Y)

2. ![1547207056824](readme/representation-Overview-and-Motivation-factor-因子乘法.png)



Q. factors VS. CPD

A. 1. CPD是贝叶斯网络的参数化

2. factors是Markov网络的参数化
3. p(A,B)=P(A) * P(B|A) 三个都看做factors --> CPD是一种特殊的factor